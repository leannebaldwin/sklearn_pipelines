{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from src.pipeline_classes import Featurizer, Imputer, Standardizer, Dummifier\n",
    "import src.model as model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/data.zip\n",
      "  inflating: data.json               \n"
     ]
    }
   ],
   "source": [
    "# unzip data.zip to inflate it into a .json file\n",
    "!unzip data/data.zip\n",
    "# move file from the working directory to the data subdirectory\n",
    "!mv data.json data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-fa4888d838fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load raw training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/data.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/galvanize/sklearn_pipelines/src/model.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"\"\"Return X and y from training data, no manipuation\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fraud'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acct_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fraud'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     cols = ['body_length', \n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    527\u001b[0m             )\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'frame'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'series'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m--> 853\u001b[0;31m                 loads(json, precise_float=self.precise_float), dtype=None)\n\u001b[0m\u001b[1;32m    854\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             decoded = {str(k): v for k, v in compat.iteritems(\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "# load raw training data\n",
    "X, y = model.load('data/data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_length</th>\n",
       "      <th>channels</th>\n",
       "      <th>country</th>\n",
       "      <th>currency</th>\n",
       "      <th>delivery_method</th>\n",
       "      <th>description</th>\n",
       "      <th>email_domain</th>\n",
       "      <th>event_created</th>\n",
       "      <th>event_end</th>\n",
       "      <th>event_published</th>\n",
       "      <th>...</th>\n",
       "      <th>ticket_types</th>\n",
       "      <th>user_age</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_type</th>\n",
       "      <th>venue_address</th>\n",
       "      <th>venue_country</th>\n",
       "      <th>venue_latitude</th>\n",
       "      <th>venue_longitude</th>\n",
       "      <th>venue_name</th>\n",
       "      <th>venue_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3852</td>\n",
       "      <td>5</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"http://s432.photobucket.com/albums...</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>1262739706</td>\n",
       "      <td>1265630400</td>\n",
       "      <td>1.263110e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'event_id': 527017, 'cost': 25.0, 'availabil...</td>\n",
       "      <td>36</td>\n",
       "      <td>1259613950</td>\n",
       "      <td>1</td>\n",
       "      <td>717 Washington Avenue</td>\n",
       "      <td>US</td>\n",
       "      <td>25.777471</td>\n",
       "      <td>-80.133433</td>\n",
       "      <td>INK Nightclub - South Beach</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3499</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;p&gt;Join us for a quick, one-night, community-b...</td>\n",
       "      <td>ruf.org</td>\n",
       "      <td>1293832670</td>\n",
       "      <td>1296288000</td>\n",
       "      <td>1.293833e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'event_id': 786878, 'cost': 35.0, 'availabil...</td>\n",
       "      <td>149</td>\n",
       "      <td>1280942776</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>US</td>\n",
       "      <td>32.776566</td>\n",
       "      <td>-79.930922</td>\n",
       "      <td>The Charleston, SC area</td>\n",
       "      <td>SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2601</td>\n",
       "      <td>8</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;h3&gt;&lt;span class=\"subcategory\"&gt;&lt;strong&gt;Teacher ...</td>\n",
       "      <td>pvsd.k12.ca.us</td>\n",
       "      <td>1291090956</td>\n",
       "      <td>1295740800</td>\n",
       "      <td>1.291092e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'event_id': 787337, 'cost': 93.51, 'availabi...</td>\n",
       "      <td>214</td>\n",
       "      <td>1272559388</td>\n",
       "      <td>3</td>\n",
       "      <td>10100 Pioneer Blvd Suite 100</td>\n",
       "      <td>US</td>\n",
       "      <td>33.944201</td>\n",
       "      <td>-118.080419</td>\n",
       "      <td>Los Angeles County Office of Education</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12347</td>\n",
       "      <td>6</td>\n",
       "      <td>IE</td>\n",
       "      <td>EUR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;p style=\"margin-bottom: 1.3em; padding-bottom...</td>\n",
       "      <td>irishtabletennis.com</td>\n",
       "      <td>1360681570</td>\n",
       "      <td>1388534400</td>\n",
       "      <td>1.360683e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'event_id': 885645, 'cost': 25.0, 'availabil...</td>\n",
       "      <td>889</td>\n",
       "      <td>1283870102</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2417</td>\n",
       "      <td>11</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;p&gt;Writers and filmmakers need to understand t...</td>\n",
       "      <td>artsandbusinesscouncil.org</td>\n",
       "      <td>1291994666</td>\n",
       "      <td>1297468800</td>\n",
       "      <td>1.291995e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'event_id': 1114349, 'cost': 150.0, 'availab...</td>\n",
       "      <td>35</td>\n",
       "      <td>1288984065</td>\n",
       "      <td>3</td>\n",
       "      <td>One Marina Park Drive</td>\n",
       "      <td>US</td>\n",
       "      <td>42.353848</td>\n",
       "      <td>-71.044276</td>\n",
       "      <td>Fish &amp; Richardson</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_length  channels country currency  delivery_method  \\\n",
       "0         3852         5      US      USD              0.0   \n",
       "1         3499         0      US      USD              1.0   \n",
       "2         2601         8      US      USD              1.0   \n",
       "3        12347         6      IE      EUR              1.0   \n",
       "4         2417        11      US      USD              0.0   \n",
       "\n",
       "                                         description  \\\n",
       "0  <p><a href=\"http://s432.photobucket.com/albums...   \n",
       "1  <p>Join us for a quick, one-night, community-b...   \n",
       "2  <h3><span class=\"subcategory\"><strong>Teacher ...   \n",
       "3  <p style=\"margin-bottom: 1.3em; padding-bottom...   \n",
       "4  <p>Writers and filmmakers need to understand t...   \n",
       "\n",
       "                 email_domain  event_created   event_end  event_published  \\\n",
       "0                   gmail.com     1262739706  1265630400     1.263110e+09   \n",
       "1                     ruf.org     1293832670  1296288000     1.293833e+09   \n",
       "2              pvsd.k12.ca.us     1291090956  1295740800     1.291092e+09   \n",
       "3        irishtabletennis.com     1360681570  1388534400     1.360683e+09   \n",
       "4  artsandbusinesscouncil.org     1291994666  1297468800     1.291995e+09   \n",
       "\n",
       "      ...                                           ticket_types  user_age  \\\n",
       "0     ...      [{'event_id': 527017, 'cost': 25.0, 'availabil...        36   \n",
       "1     ...      [{'event_id': 786878, 'cost': 35.0, 'availabil...       149   \n",
       "2     ...      [{'event_id': 787337, 'cost': 93.51, 'availabi...       214   \n",
       "3     ...      [{'event_id': 885645, 'cost': 25.0, 'availabil...       889   \n",
       "4     ...      [{'event_id': 1114349, 'cost': 150.0, 'availab...        35   \n",
       "\n",
       "   user_created  user_type                 venue_address venue_country  \\\n",
       "0    1259613950          1         717 Washington Avenue            US   \n",
       "1    1280942776          3                                          US   \n",
       "2    1272559388          3  10100 Pioneer Blvd Suite 100            US   \n",
       "3    1283870102          3                                        None   \n",
       "4    1288984065          3        One Marina Park Drive             US   \n",
       "\n",
       "  venue_latitude  venue_longitude                              venue_name  \\\n",
       "0      25.777471       -80.133433             INK Nightclub - South Beach   \n",
       "1      32.776566       -79.930922                 The Charleston, SC area   \n",
       "2      33.944201      -118.080419  Los Angeles County Office of Education   \n",
       "3            NaN              NaN                                    None   \n",
       "4      42.353848       -71.044276                       Fish & Richardson   \n",
       "\n",
       "  venue_state  \n",
       "0          FL  \n",
       "1          SC  \n",
       "2          CA  \n",
       "3        None  \n",
       "4          MA  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at data\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "Name: fraud, dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets build a pipeline and fit it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Create Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/step1.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "        ('featurizer', Featurizer()),\n",
    "        ('imputer', Imputer()),\n",
    "        ('dummifier', Dummifier()),\n",
    "        ('standardizer', Standardizer()),\n",
    "        ('model', RandomForestClassifier(n_estimators=500, \n",
    "                                         max_depth=25))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Fit the entire pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/step2.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('featurizer', Featurizer(cols=['body_length', 'channels', 'country', 'currency', 'description', 'email_domain', 'event_created', 'event_end', 'event_published', 'event_start', 'fb_published', 'has_analytics', 'has_header', 'has_logo', 'listed', 'name', 'name_length', 'object_id', 'org_desc',...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the classes and train the model\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Deploy the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a fit pipeline with a fit model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/step3.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now do one of two things:\n",
    "1. We can use the pipeline to tranform our data and use the trained model to make predictions, or\n",
    "2. We can pickle our pipeline object and move it to another machine to be used to tranform data and make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: tranform and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('data/new_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_length</th>\n",
       "      <th>channels</th>\n",
       "      <th>country</th>\n",
       "      <th>currency</th>\n",
       "      <th>delivery_method</th>\n",
       "      <th>description</th>\n",
       "      <th>email_domain</th>\n",
       "      <th>event_created</th>\n",
       "      <th>event_end</th>\n",
       "      <th>event_published</th>\n",
       "      <th>...</th>\n",
       "      <th>ticket_types</th>\n",
       "      <th>user_age</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_type</th>\n",
       "      <th>venue_address</th>\n",
       "      <th>venue_country</th>\n",
       "      <th>venue_latitude</th>\n",
       "      <th>venue_longitude</th>\n",
       "      <th>venue_name</th>\n",
       "      <th>venue_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;p&gt;&lt;span&gt;&lt;span class=\"fsl\"&gt;LOUD Championship E...</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>1365694066</td>\n",
       "      <td>1369018800</td>\n",
       "      <td>1.365694e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'event_id': 6225359, 'cost': 20.0, 'availabi...</td>\n",
       "      <td>1155</td>\n",
       "      <td>1265937792</td>\n",
       "      <td>1</td>\n",
       "      <td>905 Atlantic ave.</td>\n",
       "      <td>US</td>\n",
       "      <td>40.68097</td>\n",
       "      <td>-73.962861</td>\n",
       "      <td>Freecandy</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_length  channels country currency  delivery_method  \\\n",
       "0          432         0      US      USD              0.0   \n",
       "\n",
       "                                         description email_domain  \\\n",
       "0  <p><span><span class=\"fsl\">LOUD Championship E...    gmail.com   \n",
       "\n",
       "   event_created   event_end  event_published     ...      \\\n",
       "0     1365694066  1369018800     1.365694e+09     ...       \n",
       "\n",
       "                                        ticket_types  user_age  user_created  \\\n",
       "0  [{'event_id': 6225359, 'cost': 20.0, 'availabi...      1155    1265937792   \n",
       "\n",
       "   user_type      venue_address venue_country venue_latitude  venue_longitude  \\\n",
       "0          1  905 Atlantic ave.            US       40.68097       -73.962861   \n",
       "\n",
       "   venue_name venue_state  \n",
       "0   Freecandy          NY  \n",
       "\n",
       "[1 rows x 38 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets look at the new raw data:\n",
    "new_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/step4.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipe.predict_proba(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_probability = predictions.T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.63490814e-02, 8.00000000e-03, 0.00000000e+00, 2.12971926e-05,\n",
       "       1.07589090e-02, 2.00000000e-03, 1.38305932e-01, 0.00000000e+00,\n",
       "       2.05402746e-03, 0.00000000e+00])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show first 10 probabilities\n",
    "success_probability[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Pickle, Send, Unpickle, Transform, Predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/step5.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save `pipe` object to a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'data/pickled_pipe.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'wb') as f:\n",
    "        pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now `move` the pickle file anywhere you want!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To unpickle the `pipe` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'data/pickled_pipe.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpickled_pipe = pickle.load(open(input_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'featurizer': Featurizer(cols=['body_length', 'channels', 'country', 'currency', 'description', 'email_domain', 'event_created', 'event_end', 'event_published', 'event_start', 'fb_published', 'has_analytics', 'has_header', 'has_logo', 'listed', 'name', 'name_length', 'object_id', 'org_desc', 'org_facebook', 'org_name', 'org... 'venue_address', 'venue_country', 'venue_latitude', 'venue_longitude', 'venue_name', 'venue_state']),\n",
       " 'imputer': Imputer(cols_dict={'body_length': 'cont', 'channels': 'cat', 'country': 'cat', 'currency': 'cat', 'fb_published': 'cat', 'has_analytics': 'cat', 'has_header': 'cat', 'has_logo': 'cat', 'listed': 'cat', 'name_length': 'cont', 'payout_type': 'cat', 'sale_duration': 'cont', 'show_map': 'cat', 'user_age': 'cont', 'user_type': 'cat', 'event_duration': 'cont', 'has_payee_name': 'cat', 'has_previous_payouts': 'cat', 'has_payout_type': 'cat', 'has_facebook': 'cat', 'has_twitter': 'cat'}),\n",
       " 'dummifier': Dummifier(cols_to_dummy=['channels', 'country', 'currency', 'fb_published', 'has_analytics', 'has_header', 'has_logo', 'listed', 'payout_type', 'show_map', 'user_type', 'has_payee_name', 'has_previous_payouts', 'has_payout_type', 'has_facebook', 'has_twitter']),\n",
       " 'standardizer': Standardizer(continuous_cols=None),\n",
       " 'model': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpickled_pipe.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMMARY- All the steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/step6.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOW TO BUILD A CUSTOM PIPELINE CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PipelineClass(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, param=None):\n",
    "        self.param = param\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(X):\n",
    "        X = X.copy()\n",
    "        return X\n",
    "    \n",
    "    @staticmethod\n",
    "    def helper_function(X):\n",
    "        return X.shape\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The parameters need to be assigned in the `__init__` () method\n",
    "* The name of 'param' needs to match the name 'self.params' exactly\n",
    "* The fit method must return itself, even if there is no need to fit anything\n",
    "* the class should inherit traits from `BaseEstimator` and `TransformerMixin`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Featurizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Clean incoming df to fit into model\"\"\"\n",
    "    \n",
    "    def __init__(self, cols=None):\n",
    "        \"\"\"INPUT: a data_type_dict to determine which columns are \n",
    "                  continueous and categorical\n",
    "                  an optional cols list of columns to select\"\"\"\n",
    "        if cols==None:\n",
    "            self.cols = ['body_length', \n",
    "                            'channels', \n",
    "                            'country', \n",
    "                            'currency', \n",
    "                            'description', \n",
    "                            'email_domain', \n",
    "                            'event_created', \n",
    "                            'event_end',\n",
    "                            'event_published', \n",
    "                            'event_start', \n",
    "                            'fb_published', \n",
    "                            'has_analytics',\n",
    "                            'has_header', \n",
    "                            'has_logo', \n",
    "                            'listed', \n",
    "                            'name', \n",
    "                            'name_length', \n",
    "                            'object_id',\n",
    "                            'org_desc', \n",
    "                            'org_facebook', \n",
    "                            'org_name', \n",
    "                            'org_twitter', \n",
    "                            'payee_name',\n",
    "                            'payout_type', \n",
    "                            'previous_payouts', \n",
    "                            'sale_duration', \n",
    "                            'show_map',\n",
    "                            'ticket_types', \n",
    "                            'user_age', \n",
    "                            'user_created', \n",
    "                            'user_type',\n",
    "                            'venue_address', \n",
    "                            'venue_country', \n",
    "                            'venue_latitude', \n",
    "                            'venue_longitude',\n",
    "                            'venue_name', \n",
    "                            'venue_state']\n",
    "        else:\n",
    "            self.cols = cols\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"tranform and clean incoming training or test\"\"\"\n",
    "        df = X.copy()\n",
    "        df = df.loc[:,self.cols]\n",
    "        df['event_duration'] = df['event_end']-df['event_start']\n",
    "        df['has_payee_name'] = df['payee_name'].apply(self.is_empty)\n",
    "        df['has_header'] = df['has_header'].fillna(0)\n",
    "        df['has_previous_payouts'] = df['previous_payouts'].apply(self.is_empty)\n",
    "        df['has_payout_type'] = df['payout_type'].apply(self.is_empty)\n",
    "        df['has_facebook'] = df['org_facebook'].apply(self.is_not_zero)\n",
    "        df['has_twitter'] = df['org_twitter'].apply(self.is_not_zero)\n",
    "        df['country'] = df['country'].apply(self.replace_empty_with_none)\n",
    "        drop_list = ['description',\n",
    "                    'event_created',\n",
    "                    'event_end',\n",
    "                    'event_published',\n",
    "                    'event_start',\n",
    "                    'name',\n",
    "                    'object_id',\n",
    "                    'payee_name',\n",
    "                    'ticket_types',\n",
    "                    'user_created',\n",
    "                    'venue_address',\n",
    "                    'venue_country',\n",
    "                    'venue_longitude',\n",
    "                    'venue_latitude',\n",
    "                    'venue_name',\n",
    "                    'venue_state',\n",
    "                    'previous_payouts',\n",
    "                    'email_domain',\n",
    "                    'org_name',\n",
    "                    'org_twitter',\n",
    "                    'org_facebook',\n",
    "                    'org_desc']\n",
    "        return df.drop(drop_list, axis=1)\n",
    "\n",
    "    @staticmethod  \n",
    "    def is_not_zero(x):\n",
    "        if x == 0:\n",
    "            return 0\n",
    "        return 1\n",
    "\n",
    "    @staticmethod\n",
    "    def is_empty(x):\n",
    "        if not x:\n",
    "            return 0\n",
    "        return 1\n",
    "\n",
    "    @staticmethod\n",
    "    def max_cost(row):\n",
    "        \"\"\"Find the hightest ticket price from a row in df['ticket_types']\n",
    "        input: [{'event_id': 527017,\n",
    "                'cost': 25.0,\n",
    "                'availability': 1,\n",
    "                'quantity_total': 800,\n",
    "                'quantity_sold': 0},\n",
    "                {'event_id': 527017,\n",
    "                'cost': 50.0,\n",
    "                'availability': 1,\n",
    "                'quantity_total': 100,\n",
    "                'quantity_sold': 0},\n",
    "                {'event_id': 527017,\n",
    "                'cost': 550.0,\n",
    "                'availability': 1,\n",
    "                'quantity_total': 20,\n",
    "                'quantity_sold': 0}]\n",
    "        output: 550.0 \"\"\"\n",
    "        maximum = 0\n",
    "        for item in row:\n",
    "            if item['cost'] >= maximum:\n",
    "                maximum = item['cost']\n",
    "        return maximum\n",
    "    \n",
    "    @staticmethod\n",
    "    def replace_empty_with_none(x):\n",
    "        if not x:\n",
    "            return 'None'\n",
    "        else: \n",
    "            return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Imputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Impute either mode or mean into cleaned and dummied data\"\"\"\n",
    "    def __init__(self, cols_dict=None):\n",
    "        if cols_dict==None:\n",
    "            self.cols_dict = {'body_length':'cont', \n",
    "                                'channels':'cat', \n",
    "                                'country':'cat', \n",
    "                                'currency':'cat', \n",
    "                                'fb_published':'cat', \n",
    "                                'has_analytics':'cat', \n",
    "                                'has_header':'cat', \n",
    "                                'has_logo':'cat', \n",
    "                                'listed':'cat',\n",
    "                                'name_length':'cont', \n",
    "                                'payout_type':'cat', \n",
    "                                'sale_duration':'cont', \n",
    "                                'show_map':'cat', \n",
    "                                'user_age':'cont',\n",
    "                                'user_type':'cat', \n",
    "                                'event_duration':'cont', \n",
    "                                'has_payee_name':'cat', \n",
    "                                'has_previous_payouts':'cat',\n",
    "                                'has_payout_type':'cat', \n",
    "                                'has_facebook':'cat', \n",
    "                                'has_twitter':'cat'}\n",
    "        else:\n",
    "            self.cols_dict = cols_dict\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"save the values to impute into each column\"\"\"\n",
    "        df = X\n",
    "        self.averages = {}\n",
    "        for col, val in self.cols_dict.items():\n",
    "            if val=='cat':\n",
    "                self.averages[col] = 'None'\n",
    "            if val=='cont':\n",
    "                self.averages[col] = df.loc[:,col].mean()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"for each column in df, impute the columns mean or mode if nan\"\"\"\n",
    "        df = X.copy()\n",
    "        for col in df.columns:\n",
    "            df[col] = df[col].fillna(self.averages[col])\n",
    "        return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Dummifier(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Dummify certain columns in a DataFrame\"\"\"\n",
    "    def __init__(self, cols_to_dummy=None):\n",
    "        if cols_to_dummy==None:\n",
    "            self.cols_to_dummy = ['channels', \n",
    "                                  'country', \n",
    "                                  'currency', \n",
    "                                  'fb_published', \n",
    "                                  'has_analytics', \n",
    "                                  'has_header', \n",
    "                                  'has_logo', \n",
    "                                  'listed',\n",
    "                                  'payout_type', \n",
    "                                  'show_map', \n",
    "                                  'user_type', \n",
    "                                  'has_payee_name', \n",
    "                                  'has_previous_payouts',\n",
    "                                  'has_payout_type', \n",
    "                                  'has_facebook', \n",
    "                                  'has_twitter']\n",
    "        else:\n",
    "            self.cols_to_dummy = cols_to_dummy \n",
    "        self.unique_items = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        df = X\n",
    "        for col in self.cols_to_dummy:\n",
    "            self.unique_items[col] = df[col].unique()\n",
    "        return self\n",
    "            \n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        dummy_df = pd.DataFrame()\n",
    "        for col in self.cols_to_dummy:\n",
    "            columns = self.unique_items[col]\n",
    "            for item in columns:\n",
    "                if item==None:\n",
    "                    continue\n",
    "                dummy_df[f'{col}_{item}'] = df[col]==item\n",
    "            dummy_df = dummy_df.iloc[:,:-1]    \n",
    "        df = df.drop(self.cols_to_dummy, axis=1)\n",
    "        dummy_df = dummy_df.astype(int)\n",
    "        df = pd.concat([df, dummy_df], axis=1)\n",
    "        return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Standardizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Standardize continuous columns\"\"\"\n",
    "    def __init__(self, continuous_cols=None):\n",
    "        if continuous_cols==None:\n",
    "            self.continous_cols = ['body_length', 'name_length', \n",
    "                                   'sale_duration', 'user_age', \n",
    "                                   'event_duration']\n",
    "        else:\n",
    "            self.continous_cols = continuous_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        df = X\n",
    "        self.means = {}\n",
    "        self.standard_devs = {}\n",
    "        for col in self.continous_cols:\n",
    "            self.means[col] = df[col].mean()\n",
    "            self.standard_devs[col] = df[col].std()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        for col in self.continous_cols:\n",
    "            df[col] = (df[col]-self.means[col])/self.standard_devs[col]\n",
    "        return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTHER PIPELINE STRUCTURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn pipeline psueocode:\n",
    "\n",
    "class Pipeline():\n",
    "    def __init__(self, steps):\n",
    "    self.steps = steps\n",
    "    def fit(self, X, y=None):    \n",
    "        X = X.copy()    \n",
    "        for step in self.steps:    \n",
    "            X = step.fit_transform(X)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL GOAL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fraud_pipeline():\n",
    "    \"\"\"instantiate a pipeline object\"\"\"\n",
    "    pipeline = Pipeline([\n",
    "        ('featurizer', Featurizer()),\n",
    "        ('imputer', Imputer()),\n",
    "        ('dummifier', Dummifier()),\n",
    "        ('standardizer', Standardizer()),\n",
    "        ('model', RandomForestClassifier(n_estimators=5000, \n",
    "                                         max_depth=25))\n",
    "        ])\n",
    "    return pipeline\n",
    "\n",
    "def pickle_pipeline(pipeline, output_name):\n",
    "    \"\"\"Save fitted pipeline to pickle file\"\"\"\n",
    "    with open(output_name, 'wb') as f:\n",
    "        pickle.dump(pipeline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
